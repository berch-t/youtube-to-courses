#!/usr/bin/env python3
"""
Course Pipeline Module - Converts transcript to SOTA French course format.
Handles translation and restructuring for optimal presentation delivery.
"""
from __future__ import annotations

import os
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple

from dotenv import load_dotenv

load_dotenv()

@dataclass
class CourseConfig:
    input_path: Path
    output_path: Path
    language: str = "fr"
    style: str = "mixed"  # academic, practical, mixed
    target_duration_per_section: int = 5  # minutes
    include_exercises: bool = True
    include_glossary: bool = True


class CoursePipeline:
    def __init__(self, config: CourseConfig):
        self.config = config
        self.openai_client = None
        self._init_openai()
    
    def _init_openai(self):
        """Initialize OpenAI client"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not set in environment.")
        
        try:
            from openai import OpenAI
            self.openai_client = OpenAI(api_key=api_key)
        except ImportError:
            raise ImportError("OpenAI package not installed. Run: pip install openai")
    
    def process(self) -> Path:
        """Main processing method that converts transcript to SOTA course"""
        print("[INFO] Starting course generation pipeline...")
        
        # 1. Parse transcript
        transcript_content = self._parse_transcript()
        
        # 2. Analyze and extract structure
        structured_content = self._analyze_content_structure(transcript_content)
        
        # 3. Translate to French
        french_content = self._translate_content(structured_content)
        
        # 4. Generate course modules
        course_modules = self._generate_course_modules(french_content)
        
        # 5. Create final course document
        final_course = self._create_final_course(course_modules)
        
        # 6. Save to file
        output_file = self._save_course(final_course)
        
        print(f"[OK] SOTA Course generated: {output_file}")
        return output_file
    
    def _parse_transcript(self) -> Dict:
        """Parse the transcript markdown file"""
        content = self.config.input_path.read_text(encoding='utf-8')
        
        # Extract chunks with timestamps
        chunk_pattern = r'## Chunk \d+ \[(\d{2}:\d{2}:\d{2}) â†’ (\d{2}:\d{2}:\d{2})\]\s*\n\n(.*?)(?=\n## |$)'
        chunks = re.findall(chunk_pattern, content, re.DOTALL)
        
        transcript_data = {
            'title': self._extract_title_from_content(content),
            'total_duration': self._calculate_total_duration(chunks),
            'chunks': [
                {
                    'start_time': start,
                    'end_time': end,
                    'content': text.strip()
                }
                for start, end, text in chunks
            ]
        }
        
        return transcript_data
    
    def _extract_title_from_content(self, content: str) -> str:
        """Extract or generate a title from the content"""
        # Look for first meaningful sentence or concept
        lines = content.split('\n')
        for line in lines:
            if len(line.strip()) > 20 and 'Chunk' not in line and '#' not in line:
                # Use OpenAI to generate a title from the first meaningful content
                return self._generate_title_from_sample(line[:500])
        return "Cours IA AvancÃ©"
    
    def _generate_title_from_sample(self, sample_text: str) -> str:
        """Generate course title from sample content using OpenAI"""
        prompt = f"""
        BasÃ© sur cet extrait de transcription d'un cours, gÃ©nÃ¨re un titre accrocheur et professionnel en franÃ§ais pour le cours complet.
        Le titre doit Ãªtre:
        - PrÃ©cis et descriptif
        - Professionnel mais engageant
        - Maximum 8 mots
        - En franÃ§ais
        
        Extrait: {sample_text}
        
        RÃ©ponds seulement avec le titre, sans guillemets ni explications.
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"[WARN] Title generation failed: {e}")
            return "Cours IA AvancÃ©"
    
    def _calculate_total_duration(self, chunks: List[Tuple[str, str, str]]) -> str:
        """Calculate total duration from chunks"""
        if not chunks:
            return "00:00:00"
        
        last_end = chunks[-1][1]  # end time of last chunk
        return last_end
    
    def _analyze_content_structure(self, transcript_data: Dict) -> Dict:
        """Analyze content to identify main themes and logical structure"""
        full_content = " ".join([chunk['content'] for chunk in transcript_data['chunks']])
        
        # Use OpenAI to identify main themes and create logical structure
        analysis_prompt = f"""
        Analyse cette transcription de cours et identifie:
        1. Les thÃ¨mes principaux abordÃ©s (5-8 thÃ¨mes maximum)
        2. L'ordre logique pour un cours structurÃ©
        3. Les concepts clÃ©s pour chaque thÃ¨me
        4. Les transitions naturelles entre les thÃ¨mes
        
        Transcription: {full_content[:4000]}...
        
        RÃ©ponds au format JSON:
        {{
            "themes": [
                {{
                    "titre": "Titre du thÃ¨me",
                    "concepts_cles": ["concept1", "concept2"],
                    "duree_estimee": "10 minutes"
                }}
            ],
            "progression_logique": ["theme1", "theme2", "theme3"]
        }}
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": analysis_prompt}],
                max_tokens=1000,
                temperature=0.2
            )
            
            import json
            analysis = json.loads(response.choices[0].message.content)
            
            # Assign content chunks to themes
            structured_content = {
                'themes': analysis['themes'],
                'progression': analysis['progression_logique'],
                'content_mapping': self._map_content_to_themes(transcript_data, analysis['themes'])
            }
            
            return structured_content
            
        except Exception as e:
            print(f"[WARN] Content analysis failed: {e}")
            # Fallback to simple chronological structure
            return self._create_fallback_structure(transcript_data)
    
    def _map_content_to_themes(self, transcript_data: Dict, themes: List[Dict]) -> Dict:
        """Map transcript chunks to identified themes"""
        content_mapping = {}
        
        for i, theme in enumerate(themes):
            # Simple mapping: divide chunks evenly among themes
            chunks_per_theme = len(transcript_data['chunks']) // len(themes)
            start_idx = i * chunks_per_theme
            end_idx = (i + 1) * chunks_per_theme if i < len(themes) - 1 else len(transcript_data['chunks'])
            
            content_mapping[theme['titre']] = transcript_data['chunks'][start_idx:end_idx]
        
        return content_mapping
    
    def _create_fallback_structure(self, transcript_data: Dict) -> Dict:
        """Create a fallback structure when analysis fails"""
        chunks = transcript_data['chunks']
        themes_count = min(6, max(3, len(chunks) // 2))  # 3-6 themes
        
        themes = []
        for i in range(themes_count):
            themes.append({
                'titre': f"Module {i+1}",
                'concepts_cles': ["Concepts principaux", "Applications pratiques"],
                'duree_estimee': "8-10 minutes"
            })
        
        return {
            'themes': themes,
            'progression': [theme['titre'] for theme in themes],
            'content_mapping': self._map_content_to_themes(transcript_data, themes)
        }
    
    def _translate_content(self, structured_content: Dict) -> Dict:
        """Translate content to French and improve pedagogical structure"""
        print("[INFO] Translating and optimizing content...")
        
        translated_content = {
            'themes': [],
            'progression': structured_content['progression'],
            'content_mapping': {}
        }
        
        for theme in structured_content['themes']:
            # Translate theme metadata
            translated_theme = {
                'titre': theme['titre'],  # Already in French from analysis
                'concepts_cles': theme['concepts_cles'],
                'duree_estimee': theme['duree_estimee']
            }
            translated_content['themes'].append(translated_theme)
            
            # Translate and optimize content for this theme
            theme_chunks = structured_content['content_mapping'].get(theme['titre'], [])
            if theme_chunks:
                combined_content = " ".join([chunk['content'] for chunk in theme_chunks])
                optimized_content = self._translate_and_optimize_section(
                    combined_content, 
                    theme['titre'],
                    theme['concepts_cles']
                )
                translated_content['content_mapping'][theme['titre']] = optimized_content
        
        return translated_content
    
    def _translate_and_optimize_section(self, content: str, theme_title: str, key_concepts: List[str]) -> str:
        """Translate a section and optimize it for presentation with chunking support"""
        
        # Check content length and chunk if necessary (approximately 1 token = 4 characters)
        max_content_chars = 3000  # Conservative limit to stay under 8192 tokens total
        
        if len(content) <= max_content_chars:
            return self._translate_single_chunk(content, theme_title, key_concepts)
        else:
            # Split content into manageable chunks
            chunks = self._split_content_intelligently(content, max_content_chars)
            translated_chunks = []
            
            for i, chunk in enumerate(chunks):
                chunk_title = f"{theme_title} (Partie {i+1}/{len(chunks)})"
                translated_chunk = self._translate_single_chunk(chunk, chunk_title, key_concepts)
                translated_chunks.append(translated_chunk)
            
            return "\n\n".join(translated_chunks)

    def _split_content_intelligently(self, content: str, max_chars: int) -> List[str]:
        """Split content at natural breaking points (sentences, paragraphs)"""
        chunks = []
        
        # First try to split by paragraphs
        paragraphs = content.split('\n\n')
        current_chunk = ""
        
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) + 2 <= max_chars:
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
            else:
                # Save current chunk if not empty
                if current_chunk:
                    chunks.append(current_chunk)
                
                # If single paragraph is too long, split by sentences
                if len(paragraph) > max_chars:
                    sentence_chunks = self._split_by_sentences(paragraph, max_chars)
                    chunks.extend(sentence_chunks)
                    current_chunk = ""
                else:
                    current_chunk = paragraph
        
        # Add remaining chunk
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks

    def _split_by_sentences(self, text: str, max_chars: int) -> List[str]:
        """Split text by sentences when paragraphs are too long"""
        import re
        sentences = re.split(r'(?<=[.!?])\s+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) + 1 <= max_chars:
                if current_chunk:
                    current_chunk += " " + sentence
                else:
                    current_chunk = sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                
                # If single sentence is still too long, truncate
                if len(sentence) > max_chars:
                    chunks.append(sentence[:max_chars-3] + "...")
                else:
                    current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk)
            
        return chunks

    def _translate_single_chunk(self, content: str, theme_title: str, key_concepts: List[str]) -> str:
        """Translate a single chunk of content"""
        prompt = f"""Tu es un expert pÃ©dagogue spÃ©cialisÃ© dans la crÃ©ation de cours SOTA (State of the Art) pour des prÃ©sentations live en franÃ§ais.

TÃ¢che: Traduire et restructurer ce contenu de cours en franÃ§ais optimisÃ© pour une prÃ©sentation dynamique.

ThÃ¨me: {theme_title}
Concepts clÃ©s Ã  emphasizer: {', '.join(key_concepts)}

Contenu original: {content}

Instructions de formatting:
1. Traduis fidÃ¨lement en franÃ§ais acadÃ©mique mais accessible
2. Restructure en sections courtes (2-3 minutes chacune)
3. Utilise des listes Ã  puces pour les points clÃ©s
4. Ajoute des questions rhÃ©toriques pour engager l'audience
5. Inclus des transitions naturelles entre les idÃ©es
6. Marque les moments clÃ©s pour des pauses ou des dÃ©monstrations avec ðŸ”
7. SuggÃ¨re des exemples concrets avec ðŸ’¡
8. Indique les dÃ©finitions importantes avec ðŸ“

Format de rÃ©ponse (markdown):
### [Titre de sous-section]

[Contenu traduit et optimisÃ©]

ðŸ” **Point d'attention**: [Moment clÃ© Ã  emphasizer]

ðŸ’¡ **Exemple pratique**: [Suggestion d'exemple]

---
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"[WARN] Translation failed for {theme_title}: {e}")
            # Fallback: simple translation with chunking
            return self._simple_translate_chunked(content)
    
    def _simple_translate_chunked(self, content: str) -> str:
        """Simple translation with chunking fallback"""
        max_chunk_size = 800  # Conservative size for simple translation
        chunks = [content[i:i+max_chunk_size] for i in range(0, len(content), max_chunk_size)]
        translated_chunks = []
        
        for chunk in chunks:
            translated_chunk = self._simple_translate(chunk)
            translated_chunks.append(translated_chunk)
        
        return " ".join(translated_chunks)

    def _simple_translate(self, content: str) -> str:
        """Simple translation fallback"""
        # Truncate content to ensure we stay within token limits
        truncated_content = content[:800] if len(content) > 800 else content
        prompt = f"Traduis ce texte en franÃ§ais acadÃ©mique: {truncated_content}"
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1200,
                temperature=0.2
            )
            return response.choices[0].message.content.strip()
        except Exception:
            return content  # Return original if translation fails
    
    def _generate_course_modules(self, french_content: Dict) -> List[Dict]:
        """Generate structured course modules"""
        modules = []
        
        for i, theme_title in enumerate(french_content['progression']):
            theme_data = next((t for t in french_content['themes'] if t['titre'] == theme_title), None)
            if not theme_data:
                continue
            
            content = french_content['content_mapping'].get(theme_title, "")
            
            module = {
                'numero': i + 1,
                'titre': theme_title,
                'duree_estimee': theme_data['duree_estimee'],
                'concepts_cles': theme_data['concepts_cles'],
                'contenu': content,
                'objectifs': self._generate_learning_objectives(theme_title, content),
                'questions_reflexion': self._generate_reflection_questions(theme_title, content),
                'ressources': self._generate_additional_resources(theme_title)
            }
            
            modules.append(module)
        
        return modules
    
    def _generate_learning_objectives(self, theme_title: str, content: str) -> List[str]:
        """Generate learning objectives for a module"""
        prompt = f"""
        BasÃ© sur ce titre de module "{theme_title}" et ce contenu, gÃ©nÃ¨re 3-4 objectifs d'apprentissage clairs et mesurables en franÃ§ais.
        
        Contenu: {content[:500]}...
        
        Format: Liste de phrases commenÃ§ant par des verbes d'action (comprendre, analyser, appliquer, Ã©valuer, etc.)
        RÃ©ponds seulement avec la liste, une ligne par objectif, prÃ©fixÃ© par "- "
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3
            )
            objectives = response.choices[0].message.content.strip().split('\n')
            return [obj.strip('- ').strip() for obj in objectives if obj.strip()]
        except Exception:
            return [f"Comprendre les concepts clÃ©s de {theme_title}",
                   f"Appliquer les principes abordÃ©s dans {theme_title}"]
    
    def _generate_reflection_questions(self, theme_title: str, content: str) -> List[str]:
        """Generate reflection questions for a module"""
        prompt = f"""
        GÃ©nÃ¨re 3-4 questions de rÃ©flexion engageantes pour ce module "{theme_title}".
        Les questions doivent encourager la rÃ©flexion critique et l'application pratique.
        
        Contenu du module: {content[:500]}...
        
        RÃ©ponds seulement avec les questions, une par ligne, prÃ©fixÃ©es par "- "
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.4
            )
            questions = response.choices[0].message.content.strip().split('\n')
            return [q.strip('- ').strip() for q in questions if q.strip()]
        except Exception:
            return [f"Comment pourriez-vous appliquer {theme_title} dans votre domaine ?"]
    
    def _generate_additional_resources(self, theme_title: str) -> List[str]:
        """Generate additional resources suggestions"""
        resources = [
            "Documentation officielle des frameworks mentionnÃ©s",
            "Tutoriels pratiques et exemples de code",
            "Articles de recherche rÃ©cents sur le sujet",
            "CommunautÃ©s et forums spÃ©cialisÃ©s"
        ]
        return resources[:2]  # Keep it concise
    
    def _create_final_course(self, modules: List[Dict]) -> str:
        """Create the final course markdown document"""
        timestamp = datetime.now().strftime("%Y-%m-%d")
        
        # Calculate total duration
        total_minutes = sum([self._parse_duration(module['duree_estimee']) for module in modules])
        total_duration = f"{total_minutes} minutes ({total_minutes//60}h{total_minutes%60:02d})"
        
        # Extract course title from first module or generate one
        course_title = self._generate_course_title([module['titre'] for module in modules])
        
        course_content = f"""# {course_title}
*Cours SOTA gÃ©nÃ©rÃ© le {timestamp}*

---

## ðŸ“‹ Vue d'Ensemble du Cours

### Objectifs GÃ©nÃ©raux
Ã€ la fin de ce cours, vous serez capable de :
{self._generate_global_objectives(modules)}

### ðŸ“Š Informations Pratiques
- **DurÃ©e totale estimÃ©e** : {total_duration}
- **Format** : PrÃ©sentation interactive avec dÃ©monstrations
- **Niveau** : IntermÃ©diaire Ã  AvancÃ©
- **PrÃ©requis** : Connaissances de base en informatique et technologie

### ðŸ—ºï¸ Plan du Cours
{self._generate_course_outline(modules)}

---

"""

        # Add each module
        for module in modules:
            course_content += self._format_module(module)
        
        # Add appendices
        course_content += self._generate_appendices(modules)
        
        return course_content
    
    def _generate_course_title(self, module_titles: List[str]) -> str:
        """Generate an overarching course title"""
        prompt = f"""
        BasÃ© sur ces titres de modules de cours, gÃ©nÃ¨re un titre gÃ©nÃ©ral accrocheur et professionnel en franÃ§ais:
        
        Modules: {', '.join(module_titles)}
        
        Le titre doit Ãªtre:
        - Maximum 8 mots
        - Professionnel mais engageant
        - ReflÃ©ter le contenu global
        - En franÃ§ais
        
        RÃ©ponds seulement avec le titre.
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception:
            return "Cours d'Intelligence Artificielle AvancÃ©e"
    
    def _generate_global_objectives(self, modules: List[Dict]) -> str:
        """Generate global course objectives"""
        all_objectives = []
        for module in modules:
            all_objectives.extend(module.get('objectifs', []))
        
        # Synthesize into 4-5 global objectives
        unique_objectives = list(set(all_objectives))[:5]
        return '\n'.join([f"- {obj}" for obj in unique_objectives])
    
    def _generate_course_outline(self, modules: List[Dict]) -> str:
        """Generate course outline"""
        outline = ""
        for module in modules:
            outline += f"**Module {module['numero']}** : {module['titre']} *({module['duree_estimee']})*\n"
            key_points = module.get('concepts_cles', [])[:3]  # Top 3 key concepts
            if key_points:
                outline += f"   - {' â€¢ '.join(key_points)}\n"
            outline += "\n"
        return outline
    
    def _format_module(self, module: Dict) -> str:
        """Format a single module for the final document"""
        content = f"""## ðŸŽ¯ Module {module['numero']}: {module['titre']}
*DurÃ©e estimÃ©e: {module['duree_estimee']}*

### ðŸŽ“ Objectifs d'Apprentissage
"""
        
        for objective in module.get('objectifs', []):
            content += f"- {objective}\n"
        
        content += f"""
### ðŸ“š Contenu du Module

{module['contenu']}

### ðŸ¤” Questions de RÃ©flexion
"""
        
        for question in module.get('questions_reflexion', []):
            content += f"- {question}\n"
        
        if module.get('ressources'):
            content += "\n### ðŸ”— Ressources ComplÃ©mentaires\n"
            for resource in module['ressources']:
                content += f"- {resource}\n"
        
        content += "\n---\n\n"
        return content
    
    def _generate_appendices(self, modules: List[Dict]) -> str:
        """Generate appendices (glossary, references, etc.)"""
        appendices = f"""## ðŸ“š Annexes

### ðŸ“– Glossaire
*Termes techniques clÃ©s utilisÃ©s dans ce cours*

{self._generate_glossary(modules)}

### ðŸ”„ RÃ©sumÃ© ExÃ©cutif
*Points clÃ©s Ã  retenir de chaque module*

{self._generate_executive_summary(modules)}

### â“ Questions FrÃ©quemment PosÃ©es

**Q: Quels sont les prÃ©requis techniques pour suivre ce cours ?**
A: Des connaissances de base en informatique sont recommandÃ©es, mais le cours est conÃ§u pour Ãªtre accessible.

**Q: Comment puis-je approfondir certains sujets ?**
A: Consultez les ressources complÃ©mentaires mentionnÃ©es dans chaque module et n'hÃ©sitez pas Ã  explorer les liens fournis.

**Q: Ce cours est-il adaptÃ© aux dÃ©butants ?**
A: Ce cours vise un niveau intermÃ©diaire, mais les concepts sont expliquÃ©s de maniÃ¨re progressive.

### ðŸŽ¯ Prochaines Ã‰tapes RecommandÃ©es
- Pratiquer les concepts abordÃ©s Ã  travers des projets personnels
- Rejoindre des communautÃ©s spÃ©cialisÃ©es dans le domaine
- Continuer la veille technologique sur les derniÃ¨res avancÃ©es
- Partager vos apprentissages avec d'autres passionnÃ©s

---

*Cours gÃ©nÃ©rÃ© par le systÃ¨me SOTA Course Builder - {datetime.now().strftime("%Y-%m-%d %H:%M")}*
"""
        return appendices
    
    def _generate_glossary(self, modules: List[Dict]) -> str:
        """Generate a glossary of terms"""
        # Extract technical terms from content and generate definitions
        glossary_items = [
            "**Intelligence Artificielle (IA)** : CapacitÃ© d'une machine Ã  imiter l'intelligence humaine",
            "**Apprentissage Automatique** : MÃ©thode permettant aux machines d'apprendre sans programmation explicite",
            "**RÃ©seaux de Neurones** : ModÃ¨les computationnels inspirÃ©s du fonctionnement du cerveau humain",
            "**Traitement du Langage Naturel** : Branche de l'IA qui permet aux machines de comprendre le langage humain"
        ]
        
        return '\n'.join(glossary_items)
    
    def _generate_executive_summary(self, modules: List[Dict]) -> str:
        """Generate executive summary"""
        summary = ""
        for module in modules:
            key_concepts = module.get('concepts_cles', [])[:2]
            summary += f"**{module['titre']}** : {' â€¢ '.join(key_concepts)}\n"
        return summary
    
    def _parse_duration(self, duration_str: str) -> int:
        """Parse duration string to minutes"""
        # Extract numbers from strings like "8-10 minutes" or "10 minutes"
        import re
        numbers = re.findall(r'\d+', duration_str)
        if numbers:
            return int(numbers[0])  # Take first number
        return 10  # Default fallback
    
    def _save_course(self, course_content: str) -> Path:
        """Save the course to a file"""
        output_file = self.config.output_path
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        output_file.write_text(course_content, encoding='utf-8')
        return output_file


def create_course_pipeline(input_path: str, output_path: str, **kwargs) -> CoursePipeline:
    """Factory function to create CoursePipeline with sensible defaults"""
    config = CourseConfig(
        input_path=Path(input_path),
        output_path=Path(output_path),
        language=kwargs.get('language', 'fr'),
        style=kwargs.get('style', 'mixed'),
        target_duration_per_section=kwargs.get('target_duration_per_section', 5),
        include_exercises=kwargs.get('include_exercises', True),
        include_glossary=kwargs.get('include_glossary', True)
    )
    return CoursePipeline(config)